{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/promckkon/MK-DCNN/blob/main/MK-DCNN%20with%200dB%20NOISE%20in%20TRIAX%20Dataset%20266129.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_JTcgOD9s-GR",
        "outputId": "4f7e5836-3370-4454-aca8-836e86c53dfd"
      },
      "id": "_JTcgOD9s-GR",
      "execution_count": 250,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 251,
      "id": "1132b641",
      "metadata": {
        "id": "1132b641"
      },
      "outputs": [],
      "source": [
        "import scipy.io\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataset Input"
      ],
      "metadata": {
        "id": "2haV_hKQQOg-"
      },
      "id": "2haV_hKQQOg-"
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.DataFrame(columns=['DE_data','fault']) # upload the dataset on googledrive\n",
        "\n",
        "for root, dirs, files in os.walk(\"/content/drive/MyDrive/TRIAX_with_NOISE/TRIAX_Dataset\", topdown=False):\n",
        "    for file_name in files:\n",
        "        path = os.path.join(root, file_name)\n",
        "        print(path)\n",
        "\n",
        "        mat = scipy.io.loadmat(path)\n",
        "\n",
        "        key_name = list(mat.keys())[3]\n",
        "        DE_data = mat.get(key_name)\n",
        "        fault = np.full((len(DE_data), 1), file_name[:-4])\n",
        "\n",
        "        df_temp = pd.DataFrame({'DE_data':np.ravel(DE_data) , 'fault':np.ravel(fault)})\n",
        "\n",
        "        df = pd.concat([df,df_temp],axis=0)\n",
        "        print(df['fault'].unique())\n",
        "\n",
        "df.to_csv('/content/drive/MyDrive/MK DCNN TRIAX/NOISE_0_faults.csv',index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sXzSVyy_ylsF",
        "outputId": "8e450cab-738e-4967-face-88309de877ef"
      },
      "id": "sXzSVyy_ylsF",
      "execution_count": 252,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/TRIAX_with_NOISE/TRIAX_Dataset/F8_Normal_100W.mat\n",
            "['F8_Normal_100W']\n",
            "/content/drive/MyDrive/TRIAX_with_NOISE/TRIAX_Dataset/F1_IR007_100W.mat\n",
            "['F8_Normal_100W' 'F1_IR007_100W']\n",
            "/content/drive/MyDrive/TRIAX_with_NOISE/TRIAX_Dataset/F2_IR009_100W.mat\n",
            "['F8_Normal_100W' 'F1_IR007_100W' 'F2_IR009_100W']\n",
            "/content/drive/MyDrive/TRIAX_with_NOISE/TRIAX_Dataset/F3_IR013_100W.mat\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-4228204961.py:16: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  df = pd.concat([df,df_temp],axis=0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['F8_Normal_100W' 'F1_IR007_100W' 'F2_IR009_100W' 'F3_IR013_100W']\n",
            "/content/drive/MyDrive/TRIAX_with_NOISE/TRIAX_Dataset/F4_IR017_100W.mat\n",
            "['F8_Normal_100W' 'F1_IR007_100W' 'F2_IR009_100W' 'F3_IR013_100W'\n",
            " 'F4_IR017_100W']\n",
            "/content/drive/MyDrive/TRIAX_with_NOISE/TRIAX_Dataset/F5_OR009_100W.mat\n",
            "['F8_Normal_100W' 'F1_IR007_100W' 'F2_IR009_100W' 'F3_IR013_100W'\n",
            " 'F4_IR017_100W' 'F5_OR009_100W']\n",
            "/content/drive/MyDrive/TRIAX_with_NOISE/TRIAX_Dataset/F6_OR013_100W.mat\n",
            "['F8_Normal_100W' 'F1_IR007_100W' 'F2_IR009_100W' 'F3_IR013_100W'\n",
            " 'F4_IR017_100W' 'F5_OR009_100W' 'F6_OR013_100W']\n",
            "/content/drive/MyDrive/TRIAX_with_NOISE/TRIAX_Dataset/F7_OR017_100W.mat\n",
            "['F8_Normal_100W' 'F1_IR007_100W' 'F2_IR009_100W' 'F3_IR013_100W'\n",
            " 'F4_IR017_100W' 'F5_OR009_100W' 'F6_OR013_100W' 'F7_OR017_100W']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Multi-Kernel Deep 1D-CNN"
      ],
      "metadata": {
        "id": "2d0arbB2knS8"
      },
      "id": "2d0arbB2knS8"
    },
    {
      "cell_type": "code",
      "source": [
        "pip install tensorflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-dsJA9B5YVAW",
        "outputId": "57fee7f0-f15e-4139-d3de-a951bbcf5fe8"
      },
      "id": "-dsJA9B5YVAW",
      "execution_count": 253,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.12/dist-packages (2.19.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.12.19)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.7.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (5.29.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.32.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (4.15.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.0.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.76.0)\n",
            "Requirement already satisfied: tensorboard~=2.19.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.19.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.10.0)\n",
            "Requirement already satisfied: numpy<2.2.0,>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.0.2)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.15.1)\n",
            "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (0.18.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2026.1.4)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.1.5)\n",
            "Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "\n",
        "# Total target rows\n",
        "TARGET_ROWS = 1800\n",
        "\n",
        "# Estimate the total number of samples across all fault types\n",
        "total_samples = sum(len(df[df['fault'] == f]) for f in df['fault'].unique())\n",
        "\n",
        "# Calculate suitable window size and stride\n",
        "num_faults = 9\n",
        "average_samples_per_fault = total_samples / num_faults\n",
        "approx_windows_per_fault = TARGET_ROWS / num_faults\n",
        "stride_ratio = 0.8  # Initial stride/window ratio\n",
        "\n",
        "win_len = int(average_samples_per_fault / approx_windows_per_fault)\n",
        "stride = int(win_len * stride_ratio)\n",
        "\n",
        "X=[]\n",
        "Y=[]\n",
        "\n",
        "\n",
        "for k in df['fault'].unique():\n",
        "\n",
        "    df_temp_2 = df[df['fault']==k]\n",
        "\n",
        "    for i in np.arange(0,len(df_temp_2)-(win_len),stride):\n",
        "        temp = df_temp_2.iloc[i:i+win_len,:-1].values\n",
        "        temp = temp.reshape((1,-1))\n",
        "        X.append(temp)\n",
        "        Y.append(df_temp_2.iloc[i+win_len,-1])\n",
        "\n",
        "X=np.array(X)\n",
        "X=X.reshape((X.shape[0],-1,1))\n",
        "#X = np.repeat(X, 3, axis=3) # To repeat into 3 chanel format\n",
        "\n",
        "\n",
        "Y=np.array(Y)\n",
        "encoder= LabelEncoder()\n",
        "encoder.fit(Y)\n",
        "encoded_Y = encoder.transform(Y)\n",
        "OHE_Y = to_categorical(encoded_Y)"
      ],
      "metadata": {
        "id": "5s5vUXrUM2BH"
      },
      "id": "5s5vUXrUM2BH",
      "execution_count": 254,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train,X_test,y_train,y_test = train_test_split(X,OHE_Y,test_size=0.3,shuffle=True)"
      ],
      "metadata": {
        "id": "PreHyG2yMkTA"
      },
      "id": "PreHyG2yMkTA",
      "execution_count": 255,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense, Dropout, Flatten, Conv1D, MaxPooling1D, concatenate\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "# --- Custom Physics-Informed Loss Function ---\n",
        "def custom_loss(y_true, y_pred):\n",
        "    # Standard categorical crossentropy\n",
        "    loss = K.categorical_crossentropy(y_true, y_pred)\n",
        "\n",
        "    # Physics-Informed Term: penalize rapid class probability changes\n",
        "    # Ensure y_pred is at least 2D for slicing\n",
        "    if K.ndim(y_pred) < 2:\n",
        "        y_pred = K.expand_dims(y_pred, axis=-1)\n",
        "\n",
        "    # Ensure y_pred has more than one class dimension to compute diff\n",
        "    if K.int_shape(y_pred)[-1] > 1:\n",
        "        diff = y_pred[:, 1:] - y_pred[:, :-1]\n",
        "        squared_diff = tf.square(diff)\n",
        "        physics_term = tf.reduce_mean(squared_diff)\n",
        "    else:\n",
        "        physics_term = 0.0 # No physics term if only one class\n",
        "\n",
        "\n",
        "    # Total loss = classification loss + regularization term\n",
        "    total_loss = loss + 0.01 * physics_term  # 0.01 is tunable\n",
        "\n",
        "    return total_loss\n",
        "\n",
        "# --- Model Definition ---\n",
        "# no_classes = len(df['fault'].unique()) # Original line that caused 10 classes\n",
        "no_classes = len(encoder.classes_) # Use the encoder to get the correct number of classes\n",
        "print(f\"Number of output classes (no_classes): {no_classes}\") # Add print statement to verify\n",
        "\n",
        "input_shape = (X.shape[1], X.shape[2])  # Example: (784, 1)\n",
        "\n",
        "# Head 1\n",
        "inputs1 = Input(shape=input_shape)\n",
        "conv1 = Conv1D(filters=64, kernel_size=200, activation='relu')(inputs1)\n",
        "conv11 =(Conv1D(filters=32, kernel_size=50, activation='relu'))(conv1)\n",
        "drop1 = Dropout(0.5)(conv11)\n",
        "flat1 = Flatten()(drop1)\n",
        "\n",
        "# Head 2\n",
        "inputs2 = Input(shape=input_shape)\n",
        "conv2 = Conv1D(filters=64, kernel_size=100, activation='relu')(inputs2)\n",
        "conv21 =(Conv1D(filters=32, kernel_size=50, activation='relu'))(conv2)\n",
        "drop2 = Dropout(0.5)(conv21)\n",
        "flat2 = Flatten()(drop2)\n",
        "\n",
        "# Head 3\n",
        "inputs3 = Input(shape=input_shape)\n",
        "conv3 = Conv1D(filters=64, kernel_size=50, activation='relu')(inputs3)\n",
        "conv31 =(Conv1D(filters=32, kernel_size=50, activation='relu'))(conv3)\n",
        "drop3 = Dropout(0.5)(conv31)\n",
        "flat3 = Flatten()(drop3)\n",
        "\n",
        "# Merge all feature paths\n",
        "merged = concatenate([flat1, flat2, flat3])\n",
        "\n",
        "# Fully connected interpretation\n",
        "dense1 = Dense(50, activation='relu')(merged)\n",
        "outputs = Dense(no_classes, activation='softmax')(dense1)\n",
        "\n",
        "# Build and compile model with custom loss\n",
        "cnn_model = Model(inputs=[inputs1, inputs2, inputs3], outputs=outputs)\n",
        "cnn_model.compile(optimizer='adam', loss=custom_loss, metrics=['accuracy'])\n",
        "\n",
        "# Model summary\n",
        "cnn_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 919
        },
        "id": "kB3uGh-8J7no",
        "outputId": "8187cba8-aeb5-4eb3-f7b5-7e45cfdc5c53"
      },
      "id": "kB3uGh-8J7no",
      "execution_count": 256,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of output classes (no_classes): 8\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_263\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_263\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_57      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m614\u001b[0m, \u001b[38;5;34m1\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ input_layer_58      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m614\u001b[0m, \u001b[38;5;34m1\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ input_layer_59      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m614\u001b[0m, \u001b[38;5;34m1\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_108 (\u001b[38;5;33mConv1D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m415\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │     \u001b[38;5;34m12,864\u001b[0m │ input_layer_57[\u001b[38;5;34m0\u001b[0m… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_110 (\u001b[38;5;33mConv1D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m515\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │      \u001b[38;5;34m6,464\u001b[0m │ input_layer_58[\u001b[38;5;34m0\u001b[0m… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_112 (\u001b[38;5;33mConv1D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m565\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │      \u001b[38;5;34m3,264\u001b[0m │ input_layer_59[\u001b[38;5;34m0\u001b[0m… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_109 (\u001b[38;5;33mConv1D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m366\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │    \u001b[38;5;34m102,432\u001b[0m │ conv1d_108[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_111 (\u001b[38;5;33mConv1D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m466\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │    \u001b[38;5;34m102,432\u001b[0m │ conv1d_110[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_113 (\u001b[38;5;33mConv1D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m516\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │    \u001b[38;5;34m102,432\u001b[0m │ conv1d_112[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_68          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m366\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ conv1d_109[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_69          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m466\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ conv1d_111[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_70          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m516\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ conv1d_113[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ flatten_57          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m11712\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ dropout_68[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "│ (\u001b[38;5;33mFlatten\u001b[0m)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ flatten_58          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14912\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ dropout_69[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "│ (\u001b[38;5;33mFlatten\u001b[0m)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ flatten_59          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16512\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ dropout_70[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "│ (\u001b[38;5;33mFlatten\u001b[0m)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_5       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m43136\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ flatten_57[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ flatten_58[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], │\n",
              "│                     │                   │            │ flatten_59[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_94 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)        │  \u001b[38;5;34m2,156,850\u001b[0m │ concatenate_5[\u001b[38;5;34m0\u001b[0m]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_95 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)         │        \u001b[38;5;34m408\u001b[0m │ dense_94[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_57      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">614</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ input_layer_58      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">614</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ input_layer_59      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">614</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_108 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">415</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">12,864</span> │ input_layer_57[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_110 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">515</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">6,464</span> │ input_layer_58[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_112 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">565</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">3,264</span> │ input_layer_59[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_109 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">366</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │    <span style=\"color: #00af00; text-decoration-color: #00af00\">102,432</span> │ conv1d_108[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_111 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">466</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │    <span style=\"color: #00af00; text-decoration-color: #00af00\">102,432</span> │ conv1d_110[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_113 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">516</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │    <span style=\"color: #00af00; text-decoration-color: #00af00\">102,432</span> │ conv1d_112[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_68          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">366</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_109[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_69          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">466</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_111[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_70          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">516</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_113[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ flatten_57          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11712</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout_68[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ flatten_58          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14912</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout_69[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ flatten_59          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16512</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout_70[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_5       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">43136</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ flatten_57[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ flatten_58[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], │\n",
              "│                     │                   │            │ flatten_59[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_94 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)        │  <span style=\"color: #00af00; text-decoration-color: #00af00\">2,156,850</span> │ concatenate_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_95 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">408</span> │ dense_94[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,487,146\u001b[0m (9.49 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,487,146</span> (9.49 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,487,146\u001b[0m (9.49 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,487,146</span> (9.49 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size =200\n",
        "epochs = 60\n",
        "history = cnn_model.fit([X_train,X_train,X_train], y_train, batch_size=batch_size,epochs=epochs,verbose=1,validation_data=([X_test,X_test,X_test],y_test),shuffle=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Lxm-qvKM3oN",
        "outputId": "fc76ae8c-435f-4782-90ca-68cef3ecbdd2"
      },
      "id": "2Lxm-qvKM3oN",
      "execution_count": 257,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/60\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 943ms/step - accuracy: 0.1301 - loss: 2.2106 - val_accuracy: 0.1306 - val_loss: 2.0361\n",
            "Epoch 2/60\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - accuracy: 0.1366 - loss: 1.9776 - val_accuracy: 0.2255 - val_loss: 1.8288\n",
            "Epoch 3/60\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - accuracy: 0.2700 - loss: 1.7781 - val_accuracy: 0.3145 - val_loss: 1.5162\n",
            "Epoch 4/60\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - accuracy: 0.3398 - loss: 1.4658 - val_accuracy: 0.4036 - val_loss: 1.3079\n",
            "Epoch 5/60\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 0.4212 - loss: 1.2580 - val_accuracy: 0.5519 - val_loss: 1.1678\n",
            "Epoch 6/60\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.6425 - loss: 1.1198 - val_accuracy: 0.6573 - val_loss: 1.0136\n",
            "Epoch 7/60\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.6815 - loss: 0.9638 - val_accuracy: 0.6721 - val_loss: 0.9779\n",
            "Epoch 8/60\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.7418 - loss: 0.8883 - val_accuracy: 0.7240 - val_loss: 0.8839\n",
            "Epoch 9/60\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.7582 - loss: 0.8021 - val_accuracy: 0.7389 - val_loss: 0.8558\n",
            "Epoch 10/60\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.7864 - loss: 0.7717 - val_accuracy: 0.7923 - val_loss: 0.7042\n",
            "Epoch 11/60\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.8492 - loss: 0.6216 - val_accuracy: 0.8546 - val_loss: 0.6408\n",
            "Epoch 12/60\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.8595 - loss: 0.5927 - val_accuracy: 0.8620 - val_loss: 0.5712\n",
            "Epoch 13/60\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.8866 - loss: 0.5344 - val_accuracy: 0.9065 - val_loss: 0.5013\n",
            "Epoch 14/60\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.9135 - loss: 0.4679 - val_accuracy: 0.8932 - val_loss: 0.4826\n",
            "Epoch 15/60\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.9249 - loss: 0.4238 - val_accuracy: 0.9169 - val_loss: 0.4420\n",
            "Epoch 16/60\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.9274 - loss: 0.3896 - val_accuracy: 0.9228 - val_loss: 0.4268\n",
            "Epoch 17/60\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.9435 - loss: 0.3560 - val_accuracy: 0.8947 - val_loss: 0.4519\n",
            "Epoch 18/60\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.9332 - loss: 0.3607 - val_accuracy: 0.9273 - val_loss: 0.3984\n",
            "Epoch 19/60\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.9375 - loss: 0.3408 - val_accuracy: 0.9125 - val_loss: 0.3801\n",
            "Epoch 20/60\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.9426 - loss: 0.2747 - val_accuracy: 0.9243 - val_loss: 0.2597\n",
            "Epoch 21/60\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.9455 - loss: 0.1657 - val_accuracy: 0.9214 - val_loss: 0.2382\n",
            "Epoch 22/60\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.9524 - loss: 0.1389 - val_accuracy: 0.9199 - val_loss: 0.2244\n",
            "Epoch 23/60\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.9658 - loss: 0.1106 - val_accuracy: 0.9436 - val_loss: 0.1884\n",
            "Epoch 24/60\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.9652 - loss: 0.1172 - val_accuracy: 0.9273 - val_loss: 0.2221\n",
            "Epoch 25/60\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - accuracy: 0.9521 - loss: 0.1287 - val_accuracy: 0.9407 - val_loss: 0.1899\n",
            "Epoch 26/60\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - accuracy: 0.9651 - loss: 0.1095 - val_accuracy: 0.9154 - val_loss: 0.2449\n",
            "Epoch 27/60\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 0.9548 - loss: 0.1216 - val_accuracy: 0.8501 - val_loss: 0.3853\n",
            "Epoch 28/60\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - accuracy: 0.9422 - loss: 0.1600 - val_accuracy: 0.9258 - val_loss: 0.2148\n",
            "Epoch 29/60\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - accuracy: 0.9569 - loss: 0.1254 - val_accuracy: 0.9095 - val_loss: 0.2830\n",
            "Epoch 30/60\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - accuracy: 0.9640 - loss: 0.1009 - val_accuracy: 0.9407 - val_loss: 0.1827\n",
            "Epoch 31/60\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.9709 - loss: 0.0992 - val_accuracy: 0.9065 - val_loss: 0.2550\n",
            "Epoch 32/60\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.9691 - loss: 0.0974 - val_accuracy: 0.9184 - val_loss: 0.2311\n",
            "Epoch 33/60\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.9782 - loss: 0.0716 - val_accuracy: 0.9154 - val_loss: 0.2187\n",
            "Epoch 34/60\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.9722 - loss: 0.0721 - val_accuracy: 0.9303 - val_loss: 0.2054\n",
            "Epoch 35/60\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.9835 - loss: 0.0529 - val_accuracy: 0.9392 - val_loss: 0.1722\n",
            "Epoch 36/60\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.9795 - loss: 0.0585 - val_accuracy: 0.9392 - val_loss: 0.1907\n",
            "Epoch 37/60\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 0.9836 - loss: 0.0668 - val_accuracy: 0.9318 - val_loss: 0.2079\n",
            "Epoch 38/60\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.9778 - loss: 0.0695 - val_accuracy: 0.9332 - val_loss: 0.1937\n",
            "Epoch 39/60\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.9924 - loss: 0.0442 - val_accuracy: 0.9407 - val_loss: 0.1794\n",
            "Epoch 40/60\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.9886 - loss: 0.0451 - val_accuracy: 0.9421 - val_loss: 0.1895\n",
            "Epoch 41/60\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 0.9915 - loss: 0.0450 - val_accuracy: 0.9377 - val_loss: 0.1977\n",
            "Epoch 42/60\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.9885 - loss: 0.0449 - val_accuracy: 0.9258 - val_loss: 0.2264\n",
            "Epoch 43/60\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 0.9886 - loss: 0.0423 - val_accuracy: 0.9347 - val_loss: 0.2078\n",
            "Epoch 44/60\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.9879 - loss: 0.0465 - val_accuracy: 0.9080 - val_loss: 0.3193\n",
            "Epoch 45/60\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.9812 - loss: 0.0614 - val_accuracy: 0.9362 - val_loss: 0.1936\n",
            "Epoch 46/60\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.9833 - loss: 0.0510 - val_accuracy: 0.9362 - val_loss: 0.2018\n",
            "Epoch 47/60\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.9935 - loss: 0.0308 - val_accuracy: 0.9392 - val_loss: 0.1902\n",
            "Epoch 48/60\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.9892 - loss: 0.0401 - val_accuracy: 0.9303 - val_loss: 0.2013\n",
            "Epoch 49/60\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 0.9945 - loss: 0.0285 - val_accuracy: 0.9407 - val_loss: 0.2003\n",
            "Epoch 50/60\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - accuracy: 0.9960 - loss: 0.0255 - val_accuracy: 0.9362 - val_loss: 0.1978\n",
            "Epoch 51/60\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - accuracy: 0.9943 - loss: 0.0252 - val_accuracy: 0.9362 - val_loss: 0.2019\n",
            "Epoch 52/60\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 0.9945 - loss: 0.0224 - val_accuracy: 0.9362 - val_loss: 0.2008\n",
            "Epoch 53/60\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - accuracy: 0.9949 - loss: 0.0303 - val_accuracy: 0.9332 - val_loss: 0.2069\n",
            "Epoch 54/60\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - accuracy: 0.9941 - loss: 0.0224 - val_accuracy: 0.9392 - val_loss: 0.2004\n",
            "Epoch 55/60\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - accuracy: 0.9991 - loss: 0.0179 - val_accuracy: 0.9318 - val_loss: 0.2467\n",
            "Epoch 56/60\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 0.9958 - loss: 0.0192 - val_accuracy: 0.9392 - val_loss: 0.2098\n",
            "Epoch 57/60\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 0.9983 - loss: 0.0192 - val_accuracy: 0.9377 - val_loss: 0.1961\n",
            "Epoch 58/60\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.9985 - loss: 0.0208 - val_accuracy: 0.9362 - val_loss: 0.2070\n",
            "Epoch 59/60\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 0.9970 - loss: 0.0166 - val_accuracy: 0.9377 - val_loss: 0.1883\n",
            "Epoch 60/60\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.9991 - loss: 0.0145 - val_accuracy: 0.9362 - val_loss: 0.1974\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "def inv_transform_result(y):\n",
        "    y = y.argmax(axis=1)\n",
        "    return encoder.inverse_transform(y)\n",
        "\n",
        "# ===== 預測 =====\n",
        "y_train_pred = cnn_model.predict([X_train, X_train, X_train])\n",
        "y_test_pred  = cnn_model.predict([X_test, X_test, X_test])\n",
        "\n",
        "Y_train_pred = inv_transform_result(y_train_pred)\n",
        "Y_test_pred  = inv_transform_result(y_test_pred)\n",
        "\n",
        "Y_train_true = inv_transform_result(y_train)\n",
        "Y_test_true  = inv_transform_result(y_test)\n",
        "\n",
        "# ===== Classification Report =====\n",
        "print(\"Classification Report - Training Set:\\n\")\n",
        "print(classification_report(Y_train_true, Y_train_pred, target_names=encoder.classes_))\n",
        "\n",
        "print(\"\\nClassification Report - Test Set:\\n\")\n",
        "print(classification_report(Y_test_true, Y_test_pred, target_names=encoder.classes_))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h5pDJkEWK29x",
        "outputId": "57ceb02c-a727-46f4-9ed0-be54803d0787"
      },
      "id": "h5pDJkEWK29x",
      "execution_count": 261,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "Classification Report - Training Set:\n",
            "\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            " F1_IR007_100W       1.00      1.00      1.00       213\n",
            " F2_IR009_100W       1.00      1.00      1.00       225\n",
            " F3_IR013_100W       1.00      1.00      1.00       194\n",
            " F4_IR017_100W       1.00      1.00      1.00       190\n",
            " F5_OR009_100W       1.00      1.00      1.00       196\n",
            " F6_OR013_100W       1.00      1.00      1.00       186\n",
            " F7_OR017_100W       1.00      1.00      1.00       198\n",
            "F8_Normal_100W       1.00      1.00      1.00       170\n",
            "\n",
            "      accuracy                           1.00      1572\n",
            "     macro avg       1.00      1.00      1.00      1572\n",
            "  weighted avg       1.00      1.00      1.00      1572\n",
            "\n",
            "\n",
            "Classification Report - Test Set:\n",
            "\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            " F1_IR007_100W       0.99      0.97      0.98        78\n",
            " F2_IR009_100W       0.90      0.85      0.87        85\n",
            " F3_IR013_100W       0.95      0.93      0.94        97\n",
            " F4_IR017_100W       0.89      0.91      0.90        91\n",
            " F5_OR009_100W       1.00      0.99      0.99        90\n",
            " F6_OR013_100W       0.95      0.90      0.93        83\n",
            " F7_OR017_100W       0.84      0.95      0.89        79\n",
            "F8_Normal_100W       0.99      1.00      0.99        71\n",
            "\n",
            "      accuracy                           0.94       674\n",
            "     macro avg       0.94      0.94      0.94       674\n",
            "  weighted avg       0.94      0.94      0.94       674\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "skme6yCJK20g"
      },
      "id": "skme6yCJK20g",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.2"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}